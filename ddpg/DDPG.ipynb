{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Deep Deterministic Policy Gradient (DDPG)</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a ```Tensorflow 2.x``` implementation of DDPG. Any continuous gym environment can be used.\n",
    "Here I provide a minimal version of implementation using the ```Pendulum-v0``` environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [AshBabu](https://github.com/ashbabu)<br>\n",
    "**Date:** 01/08/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries. The Loop_handler context manager allows you to stop the iterations \n",
    "with ```Ctrl+C``` in a nice way so that the script can carry on after the loop. Credits to [Arthur Bouton](https://github.com/Bouty92/MachineLearning) for this script and a detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from looptools import Loop_handler, Monitor\n",
    "from replaybuffer import ReplayBuffer\n",
    "from actor_critic import Actor, Critic\n",
    "from ounoise import OUNoise\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg import DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "render = True\n",
    "s_dim, a_dim = env.observation_space.shape[0], env.action_space.shape[0]\n",
    "critic_lr, actor_lr = 0.002, 0.001\n",
    "total_episodes = 100\n",
    "gamma = 0.99  # Discount factor for future rewards\n",
    "tau = 0.005  # Used to update target networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch the train flag for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_ = DDPG(env, s_dim=s_dim, a_dim=a_dim, gamma=gamma, tau=tau,\n",
    "            actor_lr=actor_lr, critic_lr=critic_lr)\n",
    "if train:\n",
    "    ddpg_.train()\n",
    "else: # evaluating the trained policy\n",
    "    actor_trained = Actor(s_dim, a_dim).model()\n",
    "    actor_trained.load_weights('training/target_actor_weights')\n",
    "    s_trained, a_trained = ddpg_.collect_data(actor_trained)\n",
    "    ddpg_.plot_results(actions=a_trained, states=s_trained, train=False, title='Trained_model')\n",
    "    plt.show()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, ```u``` is the control input, $\\theta$ and $\\omega$ are respectively the joint angle and joint velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of episodic reward is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" title=\"Episodic Rewards\" src=\"avg_episodic_reward.png\" alt=\"Episodic Rewards\" width=\"300\" height=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. ***Original Paper:***     http://arxiv.org/pdf/1509.02971v2.pdf\n",
    "2. https://github.com/keras-team/keras-io/blob/master/examples/rl/ddpg_pendulum.py\n",
    "3. https://lilianweng.github.io/lil-log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTF2",
   "language": "python",
   "name": "venvtf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
